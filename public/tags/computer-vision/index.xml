<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision on Maxime Chemin</title>
    <link>http://localhost:1313/tags/computer-vision/</link>
    <description>Recent content in Computer Vision on Maxime Chemin</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/tags/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Gaze-tracking Goggles</title>
      <link>http://localhost:1313/projects/gaze-tracking-goggles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/gaze-tracking-goggles/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;&#xA;&lt;p&gt;The aim of the project was to build goggles which could find where the user was looking (gaze), the category of object the user was looking at, and the duration of attention on that object. The goggles had 3 camera modules, one on each eye to track the pupil movement and the third one for mapping the gaze to the real world. Thresholding was used to detect the pupils and contours were used to find its centre. Various important parameters such as pupil velocity, acceleration, and fixation time were calculated for further statistical analysis. &lt;strong&gt;Single Shot Descriptor&lt;/strong&gt;, with &lt;strong&gt;VGG16&lt;/strong&gt; as backbone, was used to detect the objects the user was gazing at. Additionally, a GUI was made using &lt;strong&gt;TkInter&lt;/strong&gt; for ease of use.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenQuad</title>
      <link>http://localhost:1313/projects/openquad/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/openquad/</guid>
      <description>&lt;h3 id=&#34;-githubhttpsgithubcomopenquad-rmiopenquad&#34;&gt;ðŸ”— &lt;a href=&#34;https://github.com/OpenQuad-RMI/openquad&#34;&gt;GitHub&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;&#xA;&lt;p&gt;The aim of the project is to build an open-source quadcopter platform for research in the field of drone autonomy. Various deep learning and computer vision algorithms will be implemented on the drone including person tracking, gesture control using human pose estimation, optical flow stabilization, obstacle avoidance, and depth estimation using monocular vision. The drone uses a &lt;strong&gt;Pixhawk&lt;/strong&gt; flight controller with &lt;strong&gt;Raspberry Pi&lt;/strong&gt; as a companion computer. &lt;strong&gt;DJI Flame Wheel-450&lt;/strong&gt; is used for the quadcopter frame along with some custom mountings for adding additional components.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
